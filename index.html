<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Yong Liu</title>
<style>
	.t{
		font: "Times New Roman";
		line-height: 200%;
		text-align: center;
		letter-spacing: 0px;
	}
  /* p {
	font: "Times New Roman";
	font-size: 16px;
  } */
</style>
</head>

<body>

<div class="t">
	<center>	
	<table border="0" cellpadding="0" cellspacing="0" width="800">
		<tbody><tr>
			<td colspan="4"></td>
		</tr>
		<tr>
			<td valign="bottom">
				
			</td>
			<td width="30">
				
			</td>
			<td width="200">
				<img src="./yongliu.jpg" width="120">
			</td>
			
			<td width="500">
				<font face="Times New Roman"> <b><font size="5">Yong Liu (刘镛)</font></b><p>
				
				<i>Email: <font face="Times New Roman"> <b><font size="3"><b>liu-yong20 (AT) mails.tsinghua.edu.cn</b></font></font></i>
				<!-- Email: <font size="2"><a href="mailto: wtq20@mails.tsinghua.edu.cn"><b>wtq20@mails.tsinghua.edu.cn</b></a></font></font> -->
								
			</p></td>
		</tr>
		<tr>
			<td width="50">
			</td>
			<td colspan="3" align="left" height="20" valign="top" width="750">
				<hr>
			</td>
		</tr>

		<tr>
			<td width="50">
			</td>
			<td colspan="3" align="left" height="20" valign="top" width="750">
				
				<font face="Times New Roman">
          I am currently a 3rd year Master student from <a href="https://sites.google.com/view/iigroup-thu">IIG group</a> in Tsinghua University Shenzhen International Graduate School, 
				supervised by Prof. <a href="https://scholar.google.com/citations?user=4gH3sxsAAAAJ&hl=zh-CN">Yujiu Yang</a>. 
        Previously, I received my bachelor's degree in Department of Electral Engineering from Shandong University in 2020. 
        My current research interest includes image & video segmentation, video understanding, and multi-modal understanding tasks.
        </font>

        <i><font face="Times New Roman"><h2>News</h2></font></i>
        <font face="Times New Roman">
          <li>
            2022.10: I got the <b>first prize scholarship</b> of Tsinghua University.
          </li><br>

          <li>
            2022.10: We rank first in the ECCV2022 YouTubeVIS Long Video Challenge.
          </li><br>

          <li>
            2022.10: We rank second in the ECCV2022 2nd Occluded Video Instance Segmentation Challenge.
          </li><br>

          <li>
            2022.7: Two papers on Video Object Segmentation accepted by ECCV 2022.
          </li>
        </font>
        

        <i><font face="Times New Roman"><h2>Honor and Award</h2></font></i>
        <font face="Times New Roman">
          <li>
            The first prize scholarship of Tsinghua University
          </li><br>

          <li>
          Winner of <a href="https://motcomplex.github.io/">YouTubeVIS: Long Video Challenge </a> at ECCV, 2022 
          </li><br>

          <li>
          2nd Place of <a href="https://motcomplex.github.io/">2nd Occluded Video Instance Segmentation Challenge </a> at ECCV, 2022
          </li><br>

          <li>
          3rd Place of <a href="https://youtube-vos.org/challenge/2021/">The 3rd Large-scale Video Object Segmentation Challenge </a> at CVPR, 2021
          </li>
        </font>


        <i><font face="Times New Roman"><h2>Publications</h2></font></i>
        <font face="Times New Roman">
          <ul>
          
          <li> Yong Liu, Ran Yu, Fei Yin, Xinyuan Zhao, Wei Zhao, Weihao Xia, Yujiu Yang. 
            Learning Quality-aware Dynamic Memory for Video Object Segmentation. 
            In <i><b>ECCV 2022</b></i>. &nbsp <a href="https://arxiv.org/abs/2207.07922"> Paper</a> &nbsp
            <a href="https://github.com/workforai/QDMN"> Code </a>
          </li><br>

          <li> Yong Liu, Ran Yu, Jiahao Wang, Xinyuan Zhao, Yitong Wang, Yansong Tang, Yujiu Yang. 
            Global Spectral Filter Memory Network for Video Object Segmentation.
            In <i><b>ECCV 2022</b></i>. &nbsp <a href="https://arxiv.org/abs/2210.05567"> Paper </a> &nbsp
            <a href="https://github.com/workforai/GSFM"> Code </a>
          </li><br>

          <li>
            Hui Zhou*, Yong Liu*, Jisheng Dang, Huicheng Zhen, Qiang Zhou, Shanglin Li, Yixing Zhu, Yansong Tang, Yujiu Yang.
            Class-Agnostic-Pairwise-Affinity for Semi-supervised Video Object Segmentation.
            In <i><b>CVPR 2022 Workshop </b></i>. &nbsp <a href="https://youtube-vos.org/assets/challenge/2022/reports/VOS_6th.pdf"> Paper </a>
          </li> <br>

          <li>
            Yong Liu, Ran Yu, Fei Yin, Xinyuan Zhao, Yujiu Yang.
            Quality-aware and Selective Prior Enhancement Memory Network for Video Object Segmentation.
            In <i><b>CVPR 2021 Workshop </b></i>. &nbsp <a href="https://youtube-vos.org/assets/challenge/2021/reports/VOS_3_Liu.pdf"> Paper </a>
          </li> 
          
          </ul>
        </font>
				
				<i><font face="Times New Roman"><h2>Research Internship</h2></font></i>
        <font face="Times New Roman">
				
          2022.2~Now: &nbsp ByteDance Inc. <br />
          <br>
          2021.2~2022.1: &nbsp Huawei 2012 Lab.
        </font>
                
        

				
			</td>
		</tr>
	</tbody>
	</table>
	</center>
	
</div>

                             

</body>
</html>
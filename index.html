<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yong Liu</title>
  
  <meta name="author" content="Yong Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yong Liu</name>
              </p>
              <p>I am currently a 2nd year PhD student in Tsinghua University Shenzhen International Graduate School, supervised by Prof. <a href="https://andytang15.github.io/">Yansong Tang</a>. 
                Previously, I conducted three years of master's research at Tsinghua under the supervision of Prof. <a href="https://scholar.google.com/citations?user=4gH3sxsAAAAJ&hl=zh-CN">Yujiu Yang</a>. 
                I received my bachelor's degree in Department of Electral Engineering from Shandong University in 2020. 
                <br>
                <br>
                My current research interest includes image & video segmentation, video understanding, and multi-modal understanding tasks.
              </p>
              </p>
              <p style="text-align:center">
                <a href="mailto:liu-yong20@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/Xiaohao-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/explorer-xu/">LinkedIn</a> &nbsp/&nbsp
		<a href="https://dblp.org/pid/94/7667.html">dblp</a> &nbsp/&nbsp -->
                <a href="https://github.com/yongliu20/">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=i9keb3IAAAAJ&hl=zh-CN">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yongliu.jpg"><img style="width:50%;max-width:50%" alt="profile photo" src="images/yongliu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                <b>2024-04:</b> We have won the Long-form Video Question Answering Challenge of the CVPR2024 LOVEU Workshop. Congratulations to Yiqin and Haoji!
              <li style="margin: 5px;" >
                <b>2024-04:</b> One paper has been accepted by ICMR 2024.
              <li style="margin: 5px;" >
                <b>2024-02:</b> Three papers have been accepted by CVPR 2024.
	      </li>
            </p>
          </td>
        </tr>
      </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:0px;width:100%;vertical-align:middle;padding-top: 60px">
          <heading>Preprint</heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='c5_image' style="padding-top: 30px;">
              <!-- <img src='images/QDMN.png' width="180"></div> -->
            <img src='images/dreamlight.png' width="180">
          </div>
          <script type="text/javascript">
            function dualfont_start() {
              document.getElementById('dualfont_image').style.opacity = "1";
            }
            function dualfont_stop() {
              document.getElementById('dualfont_image').style.opacity = "0";
            }
            dualfont_stop()
          </script>
        </td>
        <td style="padding:0px;width:75%;vertical-align:middle">
          <!-- <a href="https://arxiv.org/abs/2411.15869"> -->
            <papertitle>DreamLight: Towards More Harmonious and Consistent Image Relighting</papertitle>
          <!-- </a> -->
          <br>
          <strong>Yong Liu*</strong>, Wenpeng Xiao*, Qianqian Wang, Junlin Chen, Yitong Wang, Shiyin Wang, Xinglong Wu, Yansong Tang 
          <br>
          <em>Preprint
    <br>
          <!-- <a href="https://arxiv.org/abs/2411.15869">Paper</a>
          /
          <a href="https://github.com/SuleBai/SC-CLIP">Code</a> -->
          <!-- <p></p> -->
        </td>
      </tr>

      <tr style="height:20px;"></tr>
      
      <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='c5_image' style="padding-top: 30px;">
              <!-- <img src='images/QDMN.png' width="180"></div> -->
            <img src='images/openseg.png' width="180">
          </div>
          <script type="text/javascript">
            function dualfont_start() {
              document.getElementById('dualfont_image').style.opacity = "1";
            }
            function dualfont_stop() {
              document.getElementById('dualfont_image').style.opacity = "0";
            }
            dualfont_stop()
          </script>
        </td>
        <td style="padding:0px;width:75%;vertical-align:middle">
          <!-- <a href="https://arxiv.org/abs/2411.15869"> -->
            <papertitle>Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation</papertitle>
          <!-- </a> -->
          <br>
          <strong>Yong Liu*</strong>, Songli Wu*, Sule Bai*, Jiahao Wang, Yansong Tang
          <br>
          <em>Preprint
    <br>
          <!-- <a href="https://arxiv.org/abs/2411.15869">Paper</a>
          /
          <a href="https://github.com/SuleBai/SC-CLIP">Code</a> -->
          <!-- <p></p> -->
        </td>
      </tr>


      <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
        <td style="padding:0px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='c5_image' style="padding-top: 30px;">
              <!-- <img src='images/QDMN.png' width="180"></div> -->
            <img src='images/scclip.png' width="180">
          </div>
          <script type="text/javascript">
            function dualfont_start() {
              document.getElementById('dualfont_image').style.opacity = "1";
            }
            function dualfont_stop() {
              document.getElementById('dualfont_image').style.opacity = "0";
            }
            dualfont_stop()
          </script>
        </td>
        <td style="padding:0px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2411.15869">
            <papertitle>Self-Calibrated CLIP for Training-Free Open-Vocabulary Segmentation</papertitle>
          </a>
          <br>
          Sule Bai*,<strong>Yong Liu*</strong>, Yifei Han, Haoji Zhang, Yansong Tang 
          <br>
          *equal contribution
          <br>
          <em>Preprint
    <br>
          <a href="https://arxiv.org/abs/2411.15869">Paper</a>
          /
          <a href="https://github.com/SuleBai/SC-CLIP">Code</a>
          <!-- <p></p> -->
        </td>
      </tr>
      


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle;padding-top: 60px">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/UniLSeg.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2312.01623">
                <papertitle>Universal Segmentation at Arbitrary Granularity with Language Instruction</papertitle>
              </a>
              <br>
              <strong>Yong Liu</strong>, Cairong Zhang, Yitong Wang, Jiahao Wang, Yujiu Yang, Yansong Tang.
              <br>
              <em>CVPR 2024
	      <br>
              <a href="https://arxiv.org/abs/2312.01623">Paper</a>
              /
              <a href="https://github.com/workforai/UniLSeg">Code</a>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/SCAN.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2312.04089">
                <papertitle>Open-Vocabulary Segmentation with Semantic-Assisted Calibration</papertitle>
              </a>
              <br>
              <strong>Yong Liu*</strong>, Sule Bai*, Guanbin Li, Yitong Wang, Yansong Tang.
              <br>
              *equal contribution
              <br>
              <em>CVPR 2024
	      <br>
              <a href="https://arxiv.org/abs/2312.04089">Paper</a>
              /
              <a href="https://github.com/workforai/SCAN">Code</a>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="eccv22_stop()" onmouseover="eccv22_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/QDMN.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890462.pdf">
                <papertitle>Learning Quality-aware Dynamic Memory for Video Object Segmentation.</papertitle>
              </a>
              <br>
              <strong>Yong Liu</strong>, Ran Yu, Fei Yin, Xinyuan Zhao, Wei Zhao, Weihao Xia, Yujiu Yang.
              <br>
              <em>ECCV 2022
	      <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890462.pdf">Paper</a>
              /
              <a href="https://github.com/workforai/QDMN">Code</a>
              <p></p>
            </td>
          </tr>						

          <tr onmouseout="ECCV2022_stop()" onmouseover="ECCV2022_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <img src='images/GSFM.png' width="180"></div>
                <!-- <img src='images/GSFM.png' width="180"> -->
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890639.pdf">
                <papertitle>Global Spectral Filter Memory Network for Video Object Segmentation.</papertitle>
              </a>
              <br>
              <strong>Yong Liu</strong>, Ran Yu, Jiahao Wang, Xinyuan Zhao, Yitong Wang, Yansong Tang, Yujiu Yang.
              <br>
              <em>ECCV 2022
	            <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890639.pdf">Paper</a>
              /
              <a href="https://github.com/workforai/GSFM">Code</a>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/SOC.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2305.17011.pdf">
                <papertitle>SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation</papertitle>
              </a>
              <br>
              Zhuoyan Luo*, Yicheng Xiao*, <strong>Yong Liu*</strong>, Shuyan Li, Yitong Wang, Yansong Tang, Xiu Li, Yujiu Yang.
              <br>
              <strong>*equal contribution</strong>
              <br>
              <em>NeurIPS 2023
	      <br>
              <a href="https://arxiv.org/pdf/2305.17011.pdf">paper</a>
              /
              <a href="https://github.com/RobertLuo1/NeurIPS2023_SOC">Code</a>
              <p></p>
            </td>
          </tr>


          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/GKC.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2303.09181.pdf">
                <papertitle>Global Knowledge Calibration for Fast Open-Vocabulary Segmentation</papertitle>
              </a>
              <br>
              Kunyang Han*, <strong>Yong Liu*</strong>, Jun Hao Liew, Henghui Ding, Yunchao Wei, Jiajun Liu, Yitong Wang, Yansong Tang, Yujiu Yang, Jiashi Feng, Yao Zhao.
              <br>
              <strong>*equal contribution</strong>
              <br>
              <em>ICCV 2023
	      <br>
              <a href="https://arxiv.org/pdf/2303.09181.pdf">paper</a>
              <p></p>
            </td>
          </tr>			

          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/UVCOM.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.16464">
                <papertitle>Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection</papertitle>
              </a>
              <br>
              Yicheng Xiao*, Zhuoyan Luo*, <strong>Yong Liu</strong>, Yue Ma, Hengwei Bian, Yatai Ji, Yujiu Yang, Xiu Li.
              <br>
              <em>CVPR 2024
	      <br>
              <a href="https://arxiv.org/abs/2311.16464">paper</a>
              /
              <a href="https://github.com/EasonXiao-888/UVCOM">Code</a>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/RIFormer.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://techmonsterwang.github.io/RIFormer/">
                <papertitle>RIFormer: Keep Your Vision Backbone Effective But Removing Token Mixer</papertitle>
              </a>
              <br>
              Jiahao Wang, Songyang Zhang, <strong>Yong Liu</strong>, Taiqiang Wu, Yujiu Yang, Xihui Liu, Kai Chen, Ping Luo, Dahua Lin.
              <br>
              <em>CVPR 2023
	      <br>
              <a href="https://techmonsterwang.github.io/RIFormer/">Project</a>
              /
              <a href="https://arxiv.org/abs/2304.05659">Paper</a>
              /
              <a href="https://github.com/open-mmlab/mmpretrain/tree/main/configs/riformer">Code</a>
              <p></p>
            </td>
          </tr>


          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/MVTCL.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27959">
                <papertitle>Learning Multi-Scale Video-Text Correspondence for Weakly Supervised Temporal Article Gronding</papertitle>
              </a>
              <!-- <papertitle>Learning Multi-Scale Video-Text Correspondence for Weakly Supervised Temporal Article Gronding</papertitle> -->
              <br>
              Wenjia Geng, <strong>Yong Liu</strong>, Lei Chen, Sujia Wang, Jie Zhou, Yansong Tang.
              <br>
              <em>AAAI 2024
	      <!-- <br> -->
              <!-- <a href="https://arxiv.org/abs/2311.16464">paper</a> -->
              <p></p>
            </td>
          </tr>



          	


          <tr onmouseout="arxiv_stop()" onmouseover="arxiv_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image' style="padding-top: 30px;">
                  <!-- <img src='images/QDMN.png' width="180"></div> -->
                <img src='images/MORN.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }
                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2212.04873.pdf">
                <papertitle>Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition.</papertitle>
              </a>
              <br>
              Xinzhe Ni, Hao Wen, <strong>Yong Liu</strong>, Yatai Ji, Yujiu Yang.
              <br>
              <em>ICMR 2024
	      <br>
              <a href="https://arxiv.org/pdf/2212.04873.pdf">Paper</a>
              <p></p>
            </td>
          </tr>					

              

         

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle">
            <heading>Academic Challenges Award</heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="VQA_stop()" onmouseover="VQA_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/QDMN.png' width="180"></div> -->
              <img src='images/vqachallenge.png' width="150">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            Winner of the 
            <a href="https://sites.google.com/view/loveucvpr24/track1">
              <papertitle>LOVEU Workshop Track1: Challenge Long-form Video Question Answering</papertitle>
            </a>
            at CVPR, 2024.
            <br>
            Yiqin Wang*, Haoji Zhang*, Yansong Tang, <strong>Yong Liu</strong>, Jifeng Dai, Jiashi Feng, Xiaojie Jin.
              <br>
            <p></p>
          </td>
        </tr>
        
        <tr onmouseout="RefVOS_stop()" onmouseover="RefVOS_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/QDMN.png' width="180"></div> -->
              <img src='images/rvoschallenge.png' width="150">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            Winner of 
            <a href="https://youtube-vos.org/challenge/2023/leaderboard/">
              <papertitle>The 5th Large-scale Video Object Segmentation Challenge Track3: Referring Video Object Segmentation</papertitle>
            </a>
            at ICCV, 2023.
            <br>
            Zhuoyan Luo*, Yicheng Xiao*, <strong>Yong Liu*&Dagger;</strong>, Yitong Wang, Yansong Tang, Xiu Li, Yujiu Yang.
            <br>
              *equal contribution, &Dagger;Project lead
              <br>
            <p></p>
          </td>
        </tr>
        
        <tr onmouseout="LongYTB_stop()" onmouseover="LongYTB_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/QDMN.png' width="180"></div> -->
              <img src='images/longyoutubevis_certificate.png' width="150">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            Winner of 
            <a href="https://motcomplex.github.io/">
              <papertitle>YouTubeVIS Long Video Instance Challenge</papertitle>
            </a>
            at ECCV, 2022.
            <br>
            <strong>Yong Liu</strong>, Jixiang Sun, Yitong Wang, Cong Wei, Yansong Tang, Yujiu Yang.
            <p></p>
          </td>
        </tr>		
        
        
        <tr onmouseout="OVIS_stop()" onmouseover="OVIS_start()">
          <td style="padding:0px;width:25%;vertical-align:middle;margin-top:30px">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/QDMN.png' width="180"></div> -->
              <img src='images/ovis_certificate.png' width="150">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            2nd Place of 
            <a href="https://motcomplex.github.io/">
              <papertitle>Occluded Video Instance Segmentation Challenge</papertitle>
            </a>
            at ECCV, 2022.
            <br>
            <strong>Yong Liu</strong>, Jixiang Sun, Yitong Wang, Cong Wei, Yansong Tang, Yujiu Yang.
            <p></p>
          </td>
        </tr>	

        <tr onmouseout="ytbvos_stop()" onmouseover="ytbvos_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/QDMN.png' width="180"></div> -->
              <img src='images/vos_certificate.png' width="150">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            3rd Place of 
            <a href="https://motcomplex.github.io/">
              <papertitle>YouTube VOS Challenge</papertitle>
            </a>
            at CVPR, 2021.
            <br>
            <strong>Yong Liu</strong>, Ran Yu, Xinyuan Zhao, Yujiu Yang.
            <p></p>
          </td>
        </tr>	

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle;padding-top: 60px">
            <heading>Workshop Papers</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        

        <tr onmouseout="workshop1_stop()" onmouseover="workshop1_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/longyoutubevis.png' width="180"></div> -->
              <img src='images/longyoutubevis.png' width="180">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            <a href="https://motcomplex.github.io/report/ytvislong_IIG.pdf">
              <papertitle>1st Place Solution for YouTubeVIS Long Video Challenge.</papertitle>
            </a>
            <br>
            Wei Cong*, <strong>Yong Liu*</strong>, Jixiang Sun*, Yitong Wang, Yansong Tang, Yujiu Yang.
            <br>
            <em>ECCV Workshop 2022 Oral
            <br>
            <a href="https://motcomplex.github.io/report/ytvislong_IIG.pdf">Paper</a>
            <p></p>
          </td>
        </tr>    

        <tr onmouseout="workshop2_stop()" onmouseover="workshop2_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/longyoutubevis.png' width="180"></div> -->
              <img src='images/ovis.png' width="180">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            <a href="https://motcomplex.github.io/report/ovis_IIG.pdf">
              <papertitle>2nd Place Solution for OVIS Challenge.</papertitle>
            </a>
            <br>
            Jixiang Sun*, <strong>Yong Liu*</strong>, Cong Wei*, Yitong Wang, Yansong Tang, Yujiu Yang.
            <br>
            <em>ECCV Workshop 2022 Oral
            <br>
            <a href="https://motcomplex.github.io/report/ovis_IIG.pdf">Paper</a>
            <p></p>
          </td>
        </tr>  


        <tr onmouseout="workshop2_stop()" onmouseover="workshop2_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/longyoutubevis.png' width="180"></div> -->
              <img src='images/vos_3rd.png' width="180">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            <a href="https://youtube-vos.org/assets/challenge/2021/reports/VOS_3_Liu.pdf">
              <papertitle>Quality-aware and Selective Prior Enhancement Memory Network for Video Object Segmentation</papertitle>
            </a>
            <br>
            <strong>Yong Liu</strong>, Ran Yu, Xinyuan Zhao, Yujiu Yang.
            <br>
            <em>CVPR Workshop 2021 Oral
            <br>
            <a href="https://youtube-vos.org/assets/challenge/2021/reports/VOS_3_Liu.pdf">Paper</a>
            <p></p>
          </td>
        </tr>  
        

        <tr onmouseout="workshop3_stop()" onmouseover="workshop3_start()">
          <td style="padding:0px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='c5_image' style="padding-top: 30px;">
                <!-- <img src='images/longyoutubevis.png' width="180"></div> -->
              <img src='images/vos_6th.png' width="180">
            </div>
            <script type="text/javascript">
              function dualfont_start() {
                document.getElementById('dualfont_image').style.opacity = "1";
              }

              function dualfont_stop() {
                document.getElementById('dualfont_image').style.opacity = "0";
              }
              dualfont_stop()
            </script>
          </td>
          <td style="padding:0px;width:75%;vertical-align:middle">
            <a href="https://youtube-vos.org/assets/challenge/2022/reports/VOS_6th.pdf">
              <papertitle>Class-Agnostic-Pairwise-Affinity for Semi-supervised Video Object Segmentation.</papertitle>
            </a>
            <br>
            Hui Zhou*, <strong>Yong Liu*</strong>, Qiang Zhou, Shanglin Li, Yixing Zhu, Yansong Tang, Yujiu Yang.
            <br>
            <em>CVPR Workshop 2022
            <br>
            <a href="https://youtube-vos.org/assets/challenge/2022/reports/VOS_6th.pdf">Paper</a>
            <p></p>
          </td>
        </tr>
</tbody></table>
	
	
            
     				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
              <p>
                 <strong>Reviewer</strong>: 
		      <br>
		      Conference: CVPR, ICCV, ECCV, NeurIPS
		      <br>
		      Journal: TIP, TCSVT 
	  </p>
            </td>
          </tr>					
	    </tbody></table>			
		<!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		   <tr>
		    <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
		      <heading>Selected Honors</heading>
		      <p>
			 <strong>Star of Tomorrow Award</strong> from Microsoft Research Asia (Top 10% Interns at MSRA)   	(2022) 
			  <br>
			  <strong>Outstanding Undergraduate Thesis</strong> Award at HUST (Top 0.4%)	                        (2022)
			 <br>
			  <strong>Outstanding Graduates Award</strong> at HUST	                                                (2022)
			 <br>
			  <strong>Star of Scientific and Technological Innovation</strong> Award at HUST (Top 1%)        	(2020)
			 <br>
			 <strong>Hui Chuan Technology Scholarship</strong> at HUST (2 undergraduates yearly at college) 	        (2020)
			 <br>
			 <strong>Science and Technology Innovation Scholarship</strong> at HUST                             (2020-2022)
			 <br>
			 <strong>Outstanding Undergraduate in Terms of Academic Performance</strong> Award at HUST (Top 1%)	(2019)
			 </p>
		    </td>
		  </tr>					

	 </tbody></table>			
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>
		   <tr>
		    <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
		      <heading>Selected Competition Awards</heading>
		      <p>
			 <strong>National First Prize</strong> of Innovation Track at the Sixth National Youth Artificial Intelligence Innovation and Entrepreneurship Conference, <em>Chinese Association for Artificial Intelligence</em>		(2021) 
			  <br>
			  <strong>National First Prize</strong> of China Collegiate Computing Contest, <em>Ministry of Education</em>	(2020) 
			 <br>
			  <strong>Gold Medal</strong> of Citation Intent Recognition Task in WSDM Cup Algorithm Challenge, <em>the 13th ACM International Conference on Web Search and Data Mining</em>		(2020)
			 <br>
			  <strong>National First Prize</strong> of Huawei Cloud Cup AI Application Innovation Competition, <em>Huawei Corp.</em> 		(2020) 
			 <br>
			 <strong>National Champion</strong> of Innovative Thinking and Frontier Design of AI Track in DeeCamp Global AI Leader Training Program, <em>Sinovation Ventures Corp.</em>		(2020)
			 <br>
			 <strong>National First Prize</strong> of Rubik's Cube Robot Track in National University Intelligent Robot Competition, <em>Ministry of Education</em>	(2019) 
			 <br>
			 <strong>National Second Prize</strong> of China Intelligent Robot Combat Competition, <em>Ministry of Education</em>		(2019) 
			 <br>
			 <strong>National Second Runner-up Prize</strong> of DiggSci Data Mining Contest, <em>Microsoft Corp.</em>		(2019) 
			 <br>
			<strong>Honorable Mention Award</strong> of Interdisciplinary Contest in Modeling (ICM), <em>COMAP</em>		(2019) 
			 <br>
			<strong>Top Four</strong> of Central Division of RoboMaster in National Undergraduate Robot Competition, <em>DJI Corp.</em>		(2019) 
			 </p>
		    </td>
		  </tr>		

	    </tbody></table>		
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			    <tr>
			    <td style="padding:20px;width:100%;vertical-align:middle">
			      <heading>Self-made Robots</heading>
			    </td>
			  </tr>
			</tbody></table>

                 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                         <td style="padding:20px;width:50%;vertical-align:middle">                        
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/TL_V4A_qG98?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Rubik's Cube Solver.</papertitle></a>
			            <br>
				    Collaborated with my friends: F. Zuo, J. Chen, H. Zhang
                                     <br>
                                     The average time to restore a random Rubik's cube is ~5.42s.
		        </td>      
	        </tbody></table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                          <td style="padding:20px;width:50%;vertical-align:middle">                            
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/WcL-70J6f_4?autoplay=0&mute=1"   
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>

			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Nail Painting Machine.</papertitle></a>
			             <br>
				    Collaborated with my classmates: J. Luo, C. Cao.
                                     <br>
                                     
			    </td>  
	        </tbody></table>
	       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <td style="padding:20px;width:50%;vertical-align:middle">     
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/knQp0Kfn134?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Four-legged Dog.</papertitle></a>
		                     <br>
				    Collaborated with my friends at Robocon Robot Team.
                                     <br>
                                     
			    </td>  
                            <br>
                </tbody></table>
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/DOImbTi7o8Q?autoplay=0&mute=1"    
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Vision-based Self-driving Mecanum-wheeled Robot.</papertitle></a>
			           <br>
				    Collaborated with my friend: Z. Zeng.
                                     <br>
                                     
			</td> 		
                          <br>
	        </tbody></table>
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/5Y7UqpMtJCU?autoplay=0&mute=1"    
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Self-aiming-and-shooting Robot.</papertitle></a>
			           <br>
				    Collaborated with my friends at MSE-STAR Robot Team.
                                     <br>
          
			</td> 		
                          <br>
	        </tbody></table> 
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/6tyiwAx-0k0?autoplay=0&mute=1"    
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Intelligent Line Patrol Car.</papertitle></a>
			           <br>
				    Collaborated with my friends: Z. Zeng, Y. Yang.
                                     <br>
          
			</td> 		
                          <br>
	        </tbody></table>

      </tbody></table> -->
	
	

<!-- <p align="center"><font color="#999999"> Design and source code from <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman </a> and <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a></font></p>       
<p align="center"><font color="#999999">Last update: Oct. 15, 2022</font></p> -->
</body>
</html>
